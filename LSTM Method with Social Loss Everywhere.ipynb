{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76729f44",
   "metadata": {},
   "source": [
    "# LSTM with social loss everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf77ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e57e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"processed_train.npz\"\n",
    "train_data = np.load(train_path)\n",
    "test_path = \"processed_val_in.npz\"\n",
    "test_data = np.load(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9092c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim,\n",
    "                 hidden_dim,\n",
    "                 embed_dim,\n",
    "                ):\n",
    "        \n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTMCell(hidden_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, x, embedded):\n",
    "        lx = F.relu(self.linear(x))\n",
    "        embedded = self.lstm(lx, embedded)\n",
    "        return embedded\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 out_dim,\n",
    "                 hidden_dim,\n",
    "                 embed_dim,\n",
    "                ):\n",
    "        \n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(out_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTMCell(hidden_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        lx = F.relu(self.linear(x))\n",
    "        hidden = self.lstm(lx, hidden)\n",
    "        return hidden\n",
    "\n",
    "class EmbedToOutput(nn.Module):\n",
    "    def __init__(self,\n",
    "                embed_dim,\n",
    "                out_dim\n",
    "            ):\n",
    "    \n",
    "        super(EmbedToOutput, self).__init__()\n",
    "        self.linear = nn.Linear(embed_dim, out_dim)\n",
    "    \n",
    "    def forward(self, hidden):\n",
    "        out = self.linear(hidden[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9f2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "in_dim = 5\n",
    "out_dim = 2\n",
    "hidden_dim = 8\n",
    "embed_dim = 16\n",
    "learning_rate = 0.01\n",
    "decay_rate = 0.99\n",
    "num_epoch = 1000\n",
    "roll_outs = [1, 3, 10, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b41528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN, LSTM, 1dCNN, Transformer\n",
    "encoder = LSTMEncoder(in_dim = in_dim,\n",
    "               hidden_dim = hidden_dim,\n",
    "               embed_dim = embed_dim).to(device) # move model to gpu \n",
    "\n",
    "decoder = LSTMDecoder(out_dim = out_dim,\n",
    "               hidden_dim = hidden_dim,\n",
    "               embed_dim = embed_dim).to(device) # move model to gpu \n",
    "\n",
    "to_output = EmbedToOutput(embed_dim = embed_dim,\n",
    "               out_dim = out_dim).to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "to_output_optimizer = torch.optim.Adam(to_output.parameters(), lr=learning_rate)\n",
    "encoder_scheduler = torch.optim.lr_scheduler.StepLR(encoder_optimizer, step_size=1, gamma=decay_rate)\n",
    "decoder_scheduler = torch.optim.lr_scheduler.StepLR(decoder_optimizer, step_size=1, gamma=decay_rate)\n",
    "to_output_scheduler = torch.optim.lr_scheduler.StepLR(to_output_optimizer, step_size=1, gamma=decay_rate)\n",
    "loss_fun = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea183644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(encoder, decoder, to_output, encoder_optimizer, decoder_optimizer, to_output_optimizer, loss_function, roll_out):\n",
    "    train_mse = []\n",
    "    shuffler = np.random.permutation(np.arange(390 * batch_size))\n",
    "    for i in range(390):\n",
    "        batch_ids = shuffler[i * batch_size:(i+1) * batch_size]\n",
    "        inp = torch.from_numpy(train_data[\"X\"][batch_ids]).float().to(device).reshape(batch_size, 19, -1)\n",
    "        tgt = torch.from_numpy(train_data[\"y\"][batch_ids]).float().to(device).reshape(batch_size, 30, 2)\n",
    "        tgt = tgt[:, :roll_out, :]\n",
    "\n",
    "        embedded_vec = (\n",
    "            torch.zeros(batch_size, embed_dim).to(device),\n",
    "            torch.zeros(batch_size, embed_dim).to(device),\n",
    "        )\n",
    "        loss1 = 0\n",
    "        for step in range(19):\n",
    "            embedded_vec = encoder(inp[:, step, :], embedded_vec)\n",
    "            known_seq_out = to_output(embedded_vec)\n",
    "            if step != 18:\n",
    "                loss1 += loss_function(known_seq_out, inp[:, step + 1, :2])\n",
    "        loss2 = 0\n",
    "        pred = inp[:, -1, :2]\n",
    "        for step in range(roll_out):\n",
    "            embedded_vec = decoder(pred, embedded_vec)\n",
    "            pred = to_output(embedded_vec)\n",
    "            loss2 += loss_function(pred, tgt[:, step, :])\n",
    "        \n",
    "        loss = loss1 / 18 + loss2 / roll_out\n",
    "        \n",
    "        train_mse.append(loss.item()) \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        to_output_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        to_output_optimizer.step()\n",
    "        \n",
    "    train_mse = round(np.sqrt(np.mean(train_mse)),5)\n",
    "    return train_mse\n",
    "\n",
    "def eval_epoch(encoder, decoder, to_output, loss_function, roll_out):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(390, 402):\n",
    "            inp = torch.from_numpy(train_data[\"X\"][i * batch_size:(i+1) * batch_size]).float().to(device).reshape(batch_size, 19, -1)\n",
    "            tgt = torch.from_numpy(train_data[\"y\"][i * batch_size:(i+1) * batch_size]).float().to(device).reshape(batch_size, 30, 2)\n",
    "            tgt = tgt[:, :roll_out, :]\n",
    "            \n",
    "            embedded_vec = (\n",
    "                torch.zeros(batch_size, embed_dim).to(device),\n",
    "                torch.zeros(batch_size, embed_dim).to(device),\n",
    "            )\n",
    "            loss1 = 0\n",
    "            for step in range(19):\n",
    "                embedded_vec = encoder(inp[:, step, :], embedded_vec)\n",
    "                known_seq_out = to_output(embedded_vec)\n",
    "                if step != 18:\n",
    "                    loss1 += loss_function(known_seq_out, inp[:, step + 1, :2])\n",
    "            \n",
    "            loss2 = 0\n",
    "            pred = inp[:, step, :2]\n",
    "            for step in range(roll_out):\n",
    "                embedded_vec = decoder(pred, embedded_vec)\n",
    "                pred = to_output(embedded_vec)\n",
    "                loss2 += loss_function(pred, tgt[:, step, :])\n",
    "            loss = loss1 / 18 + loss2 / roll_out\n",
    "            valid_mse.append(loss.item())\n",
    "            \n",
    "        valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "    return valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcffecc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | T: 2.18 | Train RMSE: 5.54302 | Valid RMSE: 1.68683 | Current Roll Out: 1\n",
      "Epoch 2 | T: 2.16 | Train RMSE: 1.48784 | Valid RMSE: 1.03993 | Current Roll Out: 1\n",
      "Epoch 3 | T: 2.16 | Train RMSE: 1.08171 | Valid RMSE: 0.80220 | Current Roll Out: 1\n"
     ]
    }
   ],
   "source": [
    "train_rmse = []\n",
    "valid_rmse = []\n",
    "min_rmse = 10e8\n",
    "worse_count = 0\n",
    "\n",
    "roll_out_id = 0\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    start = time.time()\n",
    "\n",
    "    # model.train() # if you use dropout or batchnorm. \n",
    "    train_rmse.append(train_epoch(encoder, decoder, to_output, encoder_optimizer, decoder_optimizer, to_output_optimizer, loss_fun, roll_outs[roll_out_id]))\n",
    "\n",
    "    # model.eval()\n",
    "    val_rmse = eval_epoch(encoder, decoder, to_output, loss_fun, roll_outs[roll_out_id])\n",
    "    valid_rmse.append(val_rmse)\n",
    "\n",
    "    # save the best model\n",
    "    if valid_rmse[-1] < min_rmse:\n",
    "        min_rmse = valid_rmse[-1]\n",
    "        best_model = (encoder, decoder, to_output)\n",
    "        worse_count = 0\n",
    "        # torch.save([best_model, i, get_lr(optimizer)], name + \".pth\")\n",
    "    else:\n",
    "        worse_count += 1\n",
    "    \n",
    "    if worse_count > 10:\n",
    "        roll_out_id += 1\n",
    "        worse_count = 0\n",
    "        min_rmse = 10e8\n",
    "        encoder, decoder, to_output = best_model\n",
    "    \n",
    "    if roll_out_id >= len(roll_outs):\n",
    "        break\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    # Early Stopping\n",
    "    # if (len(train_rmse) > 100 and np.mean(valid_rmse[-5:]) >= np.mean(valid_rmse[-10:-5])):\n",
    "    #        break\n",
    "\n",
    "    # Learning Rate Decay        \n",
    "    encoder_scheduler.step()\n",
    "    decoder_scheduler.step()\n",
    "    to_output_scheduler.step()\n",
    "    \n",
    "    print(\"Epoch {} | T: {:0.2f} | Train RMSE: {:0.5f} | Valid RMSE: {:0.5f} | Current Roll Out: {}\".format(i + 1, (end-start) / 60, train_rmse[-1], valid_rmse[-1], roll_outs[roll_out_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_path(path, shift, rotation_matrix):\n",
    "    if path.ndim == 2:\n",
    "        return (np.linalg.inv(rotation_matrix) @ path.T).T + shift\n",
    "    elif path.ndim == 3:\n",
    "        path_normalize = np.zeros(path.shape)\n",
    "        for i in range(path.shape[0]):\n",
    "            path_normalize[i] = (np.linalg.inv(rotation_matrix) @ path[i].T).T + shift\n",
    "        return path_normalize\n",
    "    else:\n",
    "        raise Exception(\"Invalid dimension\")\n",
    "        \n",
    "encoder, decoder, to_output = best_model\n",
    "test_preds = []\n",
    "for i in tqdm(range(len(test_data[\"X\"]))):\n",
    "    inp = torch.from_numpy(test_data[\"X\"][i]).float().to(device).unsqueeze(0)\n",
    "    \n",
    "    embedded_vec = (\n",
    "        torch.zeros(1, embed_dim).to(device),\n",
    "        torch.zeros(1, embed_dim).to(device),\n",
    "    )\n",
    "    for step in range(19):\n",
    "        embedded_vec = encoder(inp[:, step, :], embedded_vec)\n",
    "\n",
    "    preds = []\n",
    "    pred = inp[:, step, :2]\n",
    "    for step in range(30):\n",
    "        embedded_vec = decoder(pred, embedded_vec)\n",
    "        pred = to_output(embedded_vec)\n",
    "        preds.append(pred.cpu().data.numpy())\n",
    "\n",
    "    preds = np.array(preds).reshape(30, 2)\n",
    "    \n",
    "    # De-Normalization !\n",
    "    preds = inverse_transform_path(preds, test_data[\"shifts\"][i], test_data[\"rotation_matrices\"][i])\n",
    "    test_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to int\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "predictions = np.concatenate(test_preds).reshape(len(test_preds), -1).astype(int)\n",
    "sub_df = pd.DataFrame(np.c_[sample_sub[\"ID\"], predictions], columns=[np.r_[[\"ID\"], [\"v\" + str(i) for i in range(1, 61)]]])\n",
    "sub_df.to_csv('test_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fced729",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    inp = torch.from_numpy(train_data[\"X\"][i]).float().to(device).unsqueeze(0)\n",
    "    \n",
    "    embedded_vec = (\n",
    "        torch.zeros(1, embed_dim).to(device),\n",
    "        torch.zeros(1, embed_dim).to(device),\n",
    "    )\n",
    "    for step in range(19):\n",
    "        embedded_vec = encoder(inp[:, step, :], embedded_vec)\n",
    "\n",
    "    preds = []\n",
    "    pred = inp[:, step, :2]\n",
    "    for step in range(30):\n",
    "        embedded_vec = decoder(pred, embedded_vec)\n",
    "        pred = to_output(embedded_vec)\n",
    "        preds.append(pred.cpu().data.numpy())\n",
    "\n",
    "    preds = np.array(preds).reshape(30, 2)\n",
    "    preds = inverse_transform_path(preds, train_data[\"shifts\"][i], train_data[\"rotation_matrices\"][i])\n",
    "    known = inverse_transform_path(train_data[\"X\"][i, :, :2], train_data[\"shifts\"][i], train_data[\"rotation_matrices\"][i])\n",
    "    gt = inverse_transform_path(train_data[\"y\"][i], train_data[\"shifts\"][i], train_data[\"rotation_matrices\"][i])\n",
    "    ax[i].plot(known.T[0], known.T[1], label=\"known path\")\n",
    "    ax[i].plot(gt.T[0], gt.T[1], label=\"ground truth\")\n",
    "    ax[i].plot(preds.T[0], preds.T[1], label=\"prediction\")\n",
    "    ax[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
